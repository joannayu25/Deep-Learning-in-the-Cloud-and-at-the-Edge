{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from livenessnet import LivenessNet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "#     help=\"path to input dataset\")\n",
    "# ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "#     help=\"path to trained model\")\n",
    "# ap.add_argument(\"-l\", \"--le\", type=str, required=True,\n",
    "#     help=\"path to label encoder\")\n",
    "# ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "#     help=\"path to output loss/accuracy plot\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\":\"data4/\",\n",
    "    \"model\":\"model4\",\n",
    "    \"le\":\"le4\",\n",
    "    \"plot\":\"plot4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, batch size, and number of\n",
    "# epochs to train for\n",
    "INIT_LR = 1e-4\n",
    "BS = 8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all image paths\n",
    "data = []\n",
    "labels = []\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename, load the image and\n",
    "    # resize it to be a fixed 32x32 pixels, ignoring aspect ratio\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels (which are currently strings) as integers and then\n",
    "# one-hot encode them\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(labels)\n",
    "labels = le.fit_transform(labels)\n",
    "# print(labels)\n",
    "labels = to_categorical(labels, 2)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network for 50 epochs...\n",
      "Train for 62 steps, validate on 166 samples\n",
      "Epoch 1/50\n",
      "62/62 [==============================] - 25s 406ms/step - loss: 1.1799 - accuracy: 0.5000 - val_loss: 0.6883 - val_accuracy: 0.5422\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.9998 - accuracy: 0.5625 - val_loss: 0.6629 - val_accuracy: 0.6386\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.8010 - accuracy: 0.6331 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.9249 - accuracy: 0.6331 - val_loss: 0.6489 - val_accuracy: 0.6687\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.9019 - accuracy: 0.6351 - val_loss: 0.6534 - val_accuracy: 0.6386\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.8355 - accuracy: 0.6331 - val_loss: 0.5968 - val_accuracy: 0.7048\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.8655 - accuracy: 0.6371 - val_loss: 0.5595 - val_accuracy: 0.7410\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6944 - accuracy: 0.7016 - val_loss: 0.5471 - val_accuracy: 0.7651\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.7693 - accuracy: 0.6794 - val_loss: 0.5268 - val_accuracy: 0.8072\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.8568 - accuracy: 0.6633 - val_loss: 0.5238 - val_accuracy: 0.7892\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.7374 - accuracy: 0.6855 - val_loss: 0.5212 - val_accuracy: 0.7711\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6942 - accuracy: 0.6815 - val_loss: 0.5025 - val_accuracy: 0.7771\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.6549 - accuracy: 0.7077 - val_loss: 0.5066 - val_accuracy: 0.7711\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6957 - accuracy: 0.6976 - val_loss: 0.4967 - val_accuracy: 0.7831\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.7012 - accuracy: 0.6855 - val_loss: 0.4795 - val_accuracy: 0.7952\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6477 - accuracy: 0.7036 - val_loss: 0.4795 - val_accuracy: 0.8012\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6264 - accuracy: 0.7198 - val_loss: 0.4664 - val_accuracy: 0.7952\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6479 - accuracy: 0.7480 - val_loss: 0.4209 - val_accuracy: 0.8193\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.6495 - accuracy: 0.7238 - val_loss: 0.4130 - val_accuracy: 0.8434\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6643 - accuracy: 0.7117 - val_loss: 0.3936 - val_accuracy: 0.8373\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6270 - accuracy: 0.7238 - val_loss: 0.3835 - val_accuracy: 0.8494\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.6166 - accuracy: 0.7379 - val_loss: 0.4033 - val_accuracy: 0.8494\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.5944 - accuracy: 0.7379 - val_loss: 0.4152 - val_accuracy: 0.8494\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.6162 - accuracy: 0.7460 - val_loss: 0.4101 - val_accuracy: 0.8494\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5901 - accuracy: 0.7238 - val_loss: 0.4120 - val_accuracy: 0.8373\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5783 - accuracy: 0.7379 - val_loss: 0.4032 - val_accuracy: 0.8434\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5949 - accuracy: 0.7722 - val_loss: 0.3935 - val_accuracy: 0.8494\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5442 - accuracy: 0.7621 - val_loss: 0.3825 - val_accuracy: 0.8614\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5170 - accuracy: 0.7681 - val_loss: 0.4214 - val_accuracy: 0.8313\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.5143 - accuracy: 0.7641 - val_loss: 0.3677 - val_accuracy: 0.8494\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.5562 - accuracy: 0.7500 - val_loss: 0.3349 - val_accuracy: 0.8614\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4961 - accuracy: 0.7621 - val_loss: 0.3123 - val_accuracy: 0.8675\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.4924 - accuracy: 0.7661 - val_loss: 0.2781 - val_accuracy: 0.8916\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5253 - accuracy: 0.7621 - val_loss: 0.2792 - val_accuracy: 0.8855\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.5079 - accuracy: 0.7863 - val_loss: 0.2747 - val_accuracy: 0.8855\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4528 - accuracy: 0.8044 - val_loss: 0.2704 - val_accuracy: 0.8795\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.5386 - accuracy: 0.7722 - val_loss: 0.2883 - val_accuracy: 0.8795\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4533 - accuracy: 0.7762 - val_loss: 0.2530 - val_accuracy: 0.9096\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4945 - accuracy: 0.7823 - val_loss: 0.2477 - val_accuracy: 0.9036\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4753 - accuracy: 0.8105 - val_loss: 0.2620 - val_accuracy: 0.9036\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 0.5129 - accuracy: 0.7843 - val_loss: 0.2867 - val_accuracy: 0.8916\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.4119 - accuracy: 0.8306 - val_loss: 0.2752 - val_accuracy: 0.9096\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4469 - accuracy: 0.7802 - val_loss: 0.2833 - val_accuracy: 0.9036\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.4452 - accuracy: 0.8044 - val_loss: 0.3305 - val_accuracy: 0.8434\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4681 - accuracy: 0.8246 - val_loss: 0.3234 - val_accuracy: 0.8614\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4160 - accuracy: 0.7923 - val_loss: 0.2900 - val_accuracy: 0.8795\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.4107 - accuracy: 0.8105 - val_loss: 0.2276 - val_accuracy: 0.8976\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.3910 - accuracy: 0.8306 - val_loss: 0.2333 - val_accuracy: 0.8916\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.4192 - accuracy: 0.8286 - val_loss: 0.2463 - val_accuracy: 0.9036\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.4232 - accuracy: 0.8226 - val_loss: 0.2309 - val_accuracy: 0.9036\n",
      "[INFO] evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.84      0.97      0.90        76\n",
      "       real       0.97      0.84      0.90        90\n",
      "\n",
      "avg / total       0.91      0.90      0.90       166\n",
      "\n",
      "[INFO] serializing network to 'model4'...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.25, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20, \n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.25,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = LivenessNet.build(width=32, height=32, depth=3,\n",
    "    classes=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "    predictions.argmax(axis=1), target_names=le.classes_))\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format(args[\"model\"]))\n",
    "model.save(args[\"model\"], save_format=\"h5\")\n",
    "# save the label encoder to disk\n",
    "f = open(args[\"le\"], \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
