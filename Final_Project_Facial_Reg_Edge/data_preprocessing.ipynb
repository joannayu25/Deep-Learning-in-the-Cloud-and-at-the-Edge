{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preporcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few steps for image preprocessing so we can use them for training.\n",
    "1. Image Extraction: Video recordings of a person will be extracted frame by frame and the frames will be saved as images for subsequent process\n",
    "2. Face Alignment: The images extrated will go through face detection model to extract the faces with a predefined marginal space\n",
    "3. Face Encoding: The headshots will be fed into the FaceNet model in order to get the embedding for the face. **Note: this preprocessing might be integrated into training if we are doing fine-tuning where we are adjusting the top layer of the FaceNet model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoart packages used for visulization in this notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from os.path import isdir\n",
    "from os.path import join\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the arguments. When running the code as script, one will have to use argparse or similar package to feed to arguments into the script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # Set input directory\n",
    "    # The names of the subdirectories will be the class labels\n",
    "    \"input_dir\":\"data/videos\",\n",
    "    # Set output directory\n",
    "    # The labels will be subdirectories \n",
    "    #     where extracted images are saved\n",
    "    \"output_dir\":\"data/images\",\n",
    "    \"split_types\":[\"train\", \"val\", \"test\"],\n",
    "    # Define how many frames to skip before extract each frame \n",
    "    \"skip\":100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract frames and save as images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for split in args[\"split_types\"]:\n",
    "    input_dir = join(args[\"input_dir\"], split)\n",
    "    subdirs = [subdir for subdir in os.listdir(input_dir) if isdir(join(input_dir,subdir))]\n",
    "    # print(subdirs)\n",
    "    for subdir in subdirs:\n",
    "        output_subdir = join(args[\"output_dir\"], split, subdir)\n",
    "        if not os.path.exists(output_subdir):\n",
    "            os.makedirs(output_subdir)\n",
    "        for video in os.listdir(join(input_dir,subdir)):\n",
    "            video_path = join(input_dir,subdir, video)\n",
    "            vs = cv2.VideoCapture(video_path)\n",
    "            read = 0\n",
    "            saved = 0\n",
    "            # loop over frames from the video file stream\n",
    "            while True:\n",
    "                # grab the frame from the file\n",
    "                (grabbed, frame) = vs.read()\n",
    "                # if the frame was not grabbed, then we have reached the end\n",
    "                # of the stream\n",
    "                if not grabbed:\n",
    "                    break\n",
    "                # increment the total number of frames read thus far\n",
    "                read += 1\n",
    "                # check to see if we should process this frame\n",
    "                if read % args[\"skip\"] != 0:\n",
    "                    continue\n",
    "                output_img_path = join(output_subdir,\"{}.png\".format(saved))\n",
    "                cv2.imwrite(output_img_path, frame)\n",
    "                saved += 1\n",
    "                print(\"[INFO] saved {} to disk\".format(output_img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a bunch of images, we can align the faces in those images and extract them, and again save them as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from os.path import isdir\n",
    "from os.path import join\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from src import detectors\n",
    "# from common_resources.detectors import FaceDetector\n",
    "\n",
    "\n",
    "importlib.reload(detectors)\n",
    "FaceDetector = detectors.FaceDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a few options for face detections:\n",
    "1. The detector in HW7\n",
    "2. Open CV detector\n",
    "\n",
    "Build a wrapper so we can use them in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # Set input directory\n",
    "    # The names of the subdirectories will be the class labels\n",
    "    \"input_dir\":\"data/images/\",\n",
    "    # Set output directory\n",
    "    # The labels will be subdirectories \n",
    "    #     where extracted faces are saved\n",
    "    \"output_dir\":\"data/faces/\",\n",
    "    # Define the margin (extra space) for face alignment\n",
    "    \"margin\":10,\n",
    "    \"split_types\":[\"train\", \"val\", \"test\"],\n",
    "    # Define the face detector used and paramters\n",
    "    \"detector\": (\"DLIB\",)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlib_face_detector = FaceDetector(args[\"detector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the detector of choice\n",
    "face_detector = FaceDetector(args[\"detector\"])\n",
    "margin = args[\"margin\"]\n",
    "\n",
    "for split in args[\"split_types\"]:\n",
    "    input_dir = join(args[\"input_dir\"], split)\n",
    "    subdirs = [subdir for subdir in os.listdir(input_dir) if isdir(join(input_dir,subdir))]\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        output_subdir = join(args[\"output_dir\"], split, subdir)\n",
    "        if not os.path.exists(output_subdir):\n",
    "            os.makedirs(output_subdir)\n",
    "        saved = 0\n",
    "        for file in os.listdir(join(input_dir, subdir)):\n",
    "            image_path = join(input_dir, subdir, file)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            faces = face_detector.detect_faces(image)\n",
    "            for (x,y,w,h) in faces:\n",
    "                x_start = max(0,x-margin//2)\n",
    "                y_start = max(0,y-margin//2)\n",
    "                x_end = min(image.shape[1], x+w+margin//2)\n",
    "                y_end = min(image.shape[0], y+h+margin//2)\n",
    "                cropped = image[y_start:y_end, x_start:x_end]\n",
    "                # resize the image to 160x160 for FaceNet\n",
    "                aligned = cv2.resize(cropped, (160, 160))\n",
    "                output_img_path = join(output_subdir,\"face_{}.png\".format(saved))\n",
    "                cv2.imwrite(output_img_path, aligned)\n",
    "                saved += 1\n",
    "                print(\"[INFO] saved {} to disk\".format(output_img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the faces extracted and aligned, we could encode the faces with the FaceNet model for training the SVM. Note: this step is not necessary for fine-tuning on a neural classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "from os.path import isdir\n",
    "from os.path import join\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from src import face_encoders\n",
    "\n",
    "importlib.reload(face_encoders)\n",
    "FaceEncoder = face_encoders.FaceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the model file to the tuned one if tuned FaceNet\n",
    "encoder_model = FaceEncoder(\"facenet_keras\", \"src/encoders/facenet_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    # Set input directory\n",
    "    # The names of the subdirectories will be the class labels\n",
    "    \"input_dir\":\"data/faces/\",\n",
    "    # Set output directory\n",
    "    # The labels will be subdirectories \n",
    "    #     where extracted faces are saved\n",
    "    \"output_dir\":\"data/embeddings/procees_1\",\n",
    "    \"split_types\":[\"train\", \"val\", \"test\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(args[\"output_dir\"]):\n",
    "    os.makedirs(args[\"output_dir\"])\n",
    "\n",
    "for split in args[\"split_types\"]:\n",
    "    print(f\"[INFO] Encoding faces in {split} set...\")\n",
    "    input_dir = join(args[\"input_dir\"], split)\n",
    "    subdirs = [subdir for subdir in os.listdir(input_dir) if isdir(join(input_dir,subdir))]\n",
    "    \n",
    "    faces = list()\n",
    "    embeddings = list()\n",
    "    labels = list()\n",
    "    for label in subdirs:\n",
    "        files = os.listdir(join(input_dir, label))\n",
    "        print(f'    [INFO] Encoding {len(files)} \"{label}\" faces...')\n",
    "        for file in files:\n",
    "            face_path = join(input_dir, label, file)\n",
    "            face = cv2.imread(face_path)\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face_array = np.asarray(face)\n",
    "            embedding = encoder_model.get_embedding(face_array)\n",
    "            faces.append(face_array)\n",
    "            embeddings.append(embedding)\n",
    "            labels.append(label)\n",
    "    faces = np.asarray(faces)\n",
    "    embeddings = np.asarray(embeddings)\n",
    "    labels = np.asarray(labels)\n",
    "    output_face_file = join(args[\"output_dir\"], f\"{split}_faces.npz\")\n",
    "    output_emb_file = join(args[\"output_dir\"], f\"{split}_embeddings.npz\")\n",
    "    np.savez_compressed(output_face_file, faces, labels)\n",
    "    np.savez_compressed(output_emb_file, embeddings, labels)\n",
    "    print(f\"[INFO] Saved {split} set as {output_face_file}, shape: {str(embeddings.shape)}, {str(labels.shape)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
